{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first attempts at autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our first attempt is just to get an idea of how autogluon works. we'll be doing a relatively simple prediction: given the daily frequency of crimes for a time period, predict future daily crime frequencies. namely, given the daily frequence of crimes for the previous few months, predict the next week's daily crime frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we read `crime.csv`, montgomery county's crime data, and group all the crimes that were committed in one day together. we remember to filter out data with no dates attached to them, and also get rid the columns we don't need, which amounts to almost every single one of them. this is because autogluon, at its most basic level, only needs the series name, the timestamps, and the the values of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1786967/226934276.py:1: DtypeWarning: Columns (1,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../crime.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Date_Time</th>\n",
       "      <th>target</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>130</td>\n",
       "      <td>Crimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>137</td>\n",
       "      <td>Crimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>138</td>\n",
       "      <td>Crimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>108</td>\n",
       "      <td>Crimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>125</td>\n",
       "      <td>Crimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Start_Date_Time  target   crime\n",
       "1532      2022-12-28     130  Crimes\n",
       "1316      2022-12-29     137  Crimes\n",
       "1322      2022-12-30     138  Crimes\n",
       "1347      2022-12-31     108  Crimes\n",
       "1567      2023-01-01     125  Crimes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../crime.csv\")\n",
    "df = df[df['Start_Date_Time'] != '']\n",
    "df['Start_Date_Time'] = df['Start_Date_Time'].str[:10]\n",
    "df['target'] = 1\n",
    "df = df[df.columns.intersection(['Start_Date_Time','target'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, we group all the crimes committed by the day they were committed on, and sum them to find the daily frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['Start_Date_Time'],sort=False,as_index=False).sum()\n",
    "df['crime'] = 'Crimes'\n",
    "df['Start_Date_Time'] = pd.to_datetime(df['Start_Date_Time'])\n",
    "# df = df[df['Start_Date_Time'] >= pd.to_datetime('2022-01-01')]\n",
    "df = df[df['Start_Date_Time'] <= pd.to_datetime('2023-01-01')]\n",
    "df = df.sort_values(by='Start_Date_Time')\n",
    "df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we establish covariants: checking if each day is a weekend or holiday. the reasoning goes, business days should be treated differently because of the differences in behavior between working and nonworking days. this gets put in a `known_covariates` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Crimes</th>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    weekend  holiday\n",
       "item_id timestamp                   \n",
       "Crimes  2016-07-01        0        0\n",
       "        2016-07-02        1        0\n",
       "        2016-07-03        1        0\n",
       "        2016-07-04        0        1\n",
       "        2016-07-05        0        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "known_covariates_per_item = pd.DataFrame()\n",
    "df['bc_target'] = stats.boxcox(df['target'])[0]\n",
    "known_covariates_per_item['weekend'] = df['Start_Date_Time'].dt.dayofweek // 5\n",
    "holidays = USFederalHolidayCalendar().holidays(start='2015-01-01', end='2023-01-31').to_pydatetime()\n",
    "known_covariates_per_item['holiday'] = [1 if d in holidays else 0 for d in df['Start_Date_Time']]\n",
    "known_covariates_per_item['timestamp'] = df['Start_Date_Time']\n",
    "known_covariates_per_item['item_id'] = 'Crimes'\n",
    "known_covariates = TimeSeriesDataFrame(known_covariates_per_item)\n",
    "known_covariates.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we put our data into autogluon's dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>bc_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Crimes</th>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>243</td>\n",
       "      <td>40.962081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-02</th>\n",
       "      <td>175</td>\n",
       "      <td>33.494902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-03</th>\n",
       "      <td>152</td>\n",
       "      <td>30.704962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-04</th>\n",
       "      <td>125</td>\n",
       "      <td>27.195350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-05</th>\n",
       "      <td>167</td>\n",
       "      <td>32.542749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target  bc_target\n",
       "item_id timestamp                    \n",
       "Crimes  2016-07-01     243  40.962081\n",
       "        2016-07-02     175  33.494902\n",
       "        2016-07-03     152  30.704962\n",
       "        2016-07-04     125  27.195350\n",
       "        2016-07-05     167  32.542749"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TimeSeriesDataFrame.from_data_frame(df, id_column='crime', timestamp_column='Start_Date_Time')\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training for a prediction length of 60 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./basic_total_crimes\"\n",
      "================ TimeSeriesPredictor ================\n",
      "TimeSeriesPredictor.fit() called\n",
      "Setting presets to: best_quality\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'evaluation_metric': 'sMAPE',\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 10,\n",
      "                                'scheduler': 'local',\n",
      "                                'searcher': 'auto'},\n",
      " 'hyperparameters': 'best_quality',\n",
      " 'num_cpus': 16,\n",
      " 'num_gpus': 4,\n",
      " 'prediction_length': 60,\n",
      " 'random_seed': None,\n",
      " 'target': 'target',\n",
      " 'time_limit': None}\n",
      "Provided training data set with 2376 rows, 1 items (item = single time series). Average time series length is 2376.0.\n",
      "Training artifacts will be saved to: /fs/cml-projects/teamgahsp/gahsp/basic_total_crimes\n",
      "=====================================================\n",
      "AutoGluon will save models to ./basic_total_crimes/\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'sMAPE'\n",
      "\tThis metric's sign has been flipped to adhere to being 'higher is better'. The reported score can be multiplied by -1 to get the metric value.\n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'target'\n",
      "\tpast covariates:  ['bc_target']\n",
      "tuning_data is None. Will use the last prediction_length = 60 time steps of each time series as a hold-out validation set.\n",
      "\n",
      "Starting training. Start time is 2023-02-28 17:34:08\n",
      "Models that will be trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'ARIMA', 'AutoETS', 'DynamicOptimizedTheta', 'DeepAR', 'AutoARIMA', 'TemporalFusionTransformer', 'SimpleFeedForward']\n",
      "Hyperparameter tuning model: Naive. \n",
      "\t-0.2141       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t9.84    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: SeasonalNaive. \n",
      "\t-0.1888       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t5.02    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: ETS. \n",
      "\t-0.1379       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t5.17    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: Theta. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e161300289a3445c94c68a952b030ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping HPO due to exhausted search space: 2 of 2 possible configs ran.\n",
      "\tTrained 2 models while tuning Theta.\n",
      "\t-0.1397       = Validation score (-sMAPE)\n",
      "\t10.64   s     = Total tuning time\n",
      "Hyperparameter tuning model: ARIMA. \n",
      "\t-0.1393       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t5.51    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: AutoETS. \n",
      "\t-0.1396       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t3.56    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: DynamicOptimizedTheta. \n",
      "\t-0.1345       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t12.31   s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: DeepAR. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a041e68fad74678b97ec60eb3c1618a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrained 10 models while tuning DeepAR.\n",
      "\t-0.1208       = Validation score (-sMAPE)\n",
      "\t836.00  s     = Total tuning time\n",
      "Hyperparameter tuning model: AutoARIMA. \n",
      "\t-0.1403       = Validation score (-sMAPE)\n",
      "\t0.00    s     = Training runtime\n",
      "\t1.04    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: TemporalFusionTransformer. \n",
      "\t-0.1109       = Validation score (-sMAPE)\n",
      "\t277.10  s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Hyperparameter tuning model: SimpleFeedForward. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005db0fd27194be69302c235d2a32061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping HPO due to exhausted search space: 3 of 3 possible configs ran.\n",
      "\tTrained 3 models while tuning SimpleFeedForward.\n",
      "\t-0.1221       = Validation score (-sMAPE)\n",
      "\t156.41  s     = Total tuning time\n",
      "Fitting simple weighted ensemble.\n",
      "\t-0.1084       = Validation score (-sMAPE)\n",
      "\t7.90    s     = Training runtime\n",
      "\t0.04    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta/T1', 'Theta/T2', 'ARIMA', 'AutoETS', 'DynamicOptimizedTheta', 'DeepAR/T1', 'DeepAR/T2', 'DeepAR/T3', 'DeepAR/T4', 'DeepAR/T5', 'DeepAR/T6', 'DeepAR/T7', 'DeepAR/T8', 'DeepAR/T9', 'DeepAR/T10', 'AutoARIMA', 'TemporalFusionTransformer', 'SimpleFeedForward/T1', 'SimpleFeedForward/T2', 'SimpleFeedForward/T3', 'WeightedEnsemble']\n",
      "Total runtime: 1333.20 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -0.1084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x7fb67b4e5850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length = 60, \n",
    "    path = './basic_total_crimes', \n",
    "    target = 'target',\n",
    "    known_covariates=known_covariates, \n",
    "    eval_metric = 'sMAPE',\n",
    ")\n",
    "predictor.fit(train_data, num_cpus=16, num_gpus=4, presets='best_quality')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create a plot of predicted vs. actual crime frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 123\n",
      "Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Crimes</th>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>130.317215</td>\n",
       "      <td>113.990402</td>\n",
       "      <td>121.213562</td>\n",
       "      <td>123.879776</td>\n",
       "      <td>127.400208</td>\n",
       "      <td>130.317215</td>\n",
       "      <td>133.537659</td>\n",
       "      <td>136.314896</td>\n",
       "      <td>139.532516</td>\n",
       "      <td>145.979477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>131.402832</td>\n",
       "      <td>112.377121</td>\n",
       "      <td>120.371536</td>\n",
       "      <td>124.638741</td>\n",
       "      <td>127.514870</td>\n",
       "      <td>131.402832</td>\n",
       "      <td>134.264252</td>\n",
       "      <td>137.633163</td>\n",
       "      <td>141.851959</td>\n",
       "      <td>148.212570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>130.862000</td>\n",
       "      <td>110.970032</td>\n",
       "      <td>118.468414</td>\n",
       "      <td>123.791756</td>\n",
       "      <td>127.137558</td>\n",
       "      <td>130.862000</td>\n",
       "      <td>134.215042</td>\n",
       "      <td>138.417145</td>\n",
       "      <td>142.865021</td>\n",
       "      <td>148.507538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>130.833069</td>\n",
       "      <td>112.259338</td>\n",
       "      <td>118.840408</td>\n",
       "      <td>124.109718</td>\n",
       "      <td>127.742043</td>\n",
       "      <td>130.833069</td>\n",
       "      <td>134.650208</td>\n",
       "      <td>138.892761</td>\n",
       "      <td>142.935974</td>\n",
       "      <td>148.214874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>130.501740</td>\n",
       "      <td>113.000824</td>\n",
       "      <td>119.075005</td>\n",
       "      <td>123.638550</td>\n",
       "      <td>127.941025</td>\n",
       "      <td>130.501740</td>\n",
       "      <td>134.818542</td>\n",
       "      <td>138.397980</td>\n",
       "      <td>142.657990</td>\n",
       "      <td>147.324402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean         0.1         0.2         0.3  \\\n",
       "item_id timestamp                                                    \n",
       "Crimes  2023-01-02  130.317215  113.990402  121.213562  123.879776   \n",
       "        2023-01-03  131.402832  112.377121  120.371536  124.638741   \n",
       "        2023-01-04  130.862000  110.970032  118.468414  123.791756   \n",
       "        2023-01-05  130.833069  112.259338  118.840408  124.109718   \n",
       "        2023-01-06  130.501740  113.000824  119.075005  123.638550   \n",
       "\n",
       "                           0.4         0.5         0.6         0.7  \\\n",
       "item_id timestamp                                                    \n",
       "Crimes  2023-01-02  127.400208  130.317215  133.537659  136.314896   \n",
       "        2023-01-03  127.514870  131.402832  134.264252  137.633163   \n",
       "        2023-01-04  127.137558  130.862000  134.215042  138.417145   \n",
       "        2023-01-05  127.742043  130.833069  134.650208  138.892761   \n",
       "        2023-01-06  127.941025  130.501740  134.818542  138.397980   \n",
       "\n",
       "                           0.8         0.9  \n",
       "item_id timestamp                           \n",
       "Crimes  2023-01-02  139.532516  145.979477  \n",
       "        2023-01-03  141.851959  148.212570  \n",
       "        2023-01-04  142.865021  148.507538  \n",
       "        2023-01-05  142.935974  148.214874  \n",
       "        2023-01-06  142.657990  147.324402  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = predictor.predict(train_data)\n",
    "predictions.head()\n",
    "\n",
    "test_data = pd.read_csv(\"../crime.csv\")\n",
    "test_data = test_data[test_data['Start_Date_Time'] != '']\n",
    "test_data['Start_Date_Time'] = test_data['Start_Date_Time'].str[:10]\n",
    "test_data['target'] = 1\n",
    "test_data = test_data[test_data.columns.intersection(['Start_Date_Time','target'])]\n",
    "test_data = test_data.groupby(['Start_Date_Time'],sort=False,as_index=False).sum()\n",
    "test_data['crime'] = 'Crimes'\n",
    "test_data['Start_Date_Time'] = pd.to_datetime(test_data['Start_Date_Time'])\n",
    "test_data = test_data.sort_values(by='Start_Date_Time')\n",
    "test_data = test_data[test_data['Start_Date_Time'] >= pd.to_datetime('2022-01-01')]\n",
    "test_data = test_data[test_data['Start_Date_Time'] <= pd.to_datetime('2023-03-31')]\n",
    "test_data = TimeSeriesDataFrame.from_data_frame(test_data, id_column='crime', timestamp_column='Start_Date_Time')\n",
    "\n",
    "item_id = 'Crimes'\n",
    "y_past = train_data.loc[item_id]['target']\n",
    "y_pred = predictions.loc[item_id]\n",
    "y_test = test_data.loc[item_id]['target'][-53:]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# plt.plot(y_past, label='Past time series values')\n",
    "plt.plot(y_pred['mean'], label='Mean forecast')\n",
    "plt.plot(y_test, label='Future time series values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
